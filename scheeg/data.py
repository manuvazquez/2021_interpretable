# AUTOGENERATED! DO NOT EDIT! File to edit: 10_data.ipynb (unless otherwise specified).

__all__ = ['read_matlab', 'average_frequencies', 'average_frequencies_and_normalize', 'to_rgb', 'write_image_files',
           'concatenate', 'images_to_vectors', 'to_df']

# Cell
import pathlib
from typing import Dict, List, Union, Optional

import numpy as np
import pandas as pd
import torch
import scipy.io
from PIL import Image

# Cell
def read_matlab(input_file: Union[str, pathlib.Path]) -> dict:
    """
    Read data from MATLAB file while performing some checks.

    **Parameters**

    - `input_file`: str or pathlib

        Path to the input file.

    **Returns**

    - `res`: dict

        Every key is associated with a different variable.

    - `shape`: tuple

        The shape of *every* array in the dictionary.
    """

    res = {k: v for k, v in scipy.io.loadmat(input_file).items() if not k.startswith('__')}

    shape = next(iter(res.values())).shape

    for v in res.values():

        assert v.shape == shape

    return res, shape

# Cell
def average_frequencies(data: np.ndarray, freqs: list) -> np.ndarray:
    """
    Average frequencies in an array.

    **Parameters**

    - `data`: numpy ndarray

        Raw images.

    - `freqs`: list

        Each element is a list yielding a collection of indexes that are to be averaged.

    **Returns**

    - `out`: numpy ndarray

        An array with the same number of dimensions.
    """

    return np.stack([data[..., f, :].mean(axis=-2) for f in freqs], axis=3)

# Cell
def average_frequencies_and_normalize(metric: np.ndarray, freqs: list, normalize_on: str = 'subjects') -> np.ndarray:

    averaged_freqs = average_frequencies(metric, freqs)

    if normalize_on == 'subjects':

        # maximum over every dimension except that for subjects
        max_over_channels_freq_samples = metric.max(axis=(1, 2, 3, 4))

        return averaged_freqs / max_over_channels_freq_samples[:, np.newaxis, np.newaxis, np.newaxis, np.newaxis]

    elif normalize_on == 'subjects and channels':

        # maximum over frequencies and samples
        max_over_freq_samples = metric.max(axis=(3, 4))

        return averaged_freqs / max_over_freq_samples[:, :, :, np.newaxis, np.newaxis]

    else:

        raise Exception('invalid value of "normalize_on" parameter')

# Cell
def to_rgb(array: np.ndarray) -> np.ndarray:

    return (array * 255).astype(np.uint8)

# Cell
def write_image_files(data: Dict[str, np.ndarray], output_dir: [str, pathlib.Path], i_test: list = []):

    i_test = set(i_test)
    output_dir = pathlib.Path(output_dir)

    # loop over the *classes* (labels) in the dictionary
    for c, c_data in data.items():

        for i_subject, subject_data in enumerate(c_data):

            # different directories for training/validation and test datasets
            train_or_test = 'test' if i_subject in i_test else 'train'

            subject_dir = output_dir / train_or_test / c / str(i_subject)

            subject_dir.mkdir(parents=True, exist_ok=True)

            # `np.moveaxis` since the different samples in `subject_data` are in the last dimension
            for i_sample, sample in enumerate(np.moveaxis(subject_data, -1, 0)):

                im = Image.fromarray(sample)
                im.save(subject_dir / (str(i_sample) + '.jpg'))

# Cell
def concatenate(data: dict, *left_right_name) -> dict:

    res = dict()

    for left, right, name in left_right_name:

        shape = data[left].shape
        assert shape == data[right].shape

        new_shape = shape[:2] + (shape[2]*2,) + shape[3:]

        res[name] = np.empty(new_shape)
        res[name][:, :, :shape[1], ...] = data[left]
        res[name][:, :, shape[1]:, ...] = data[right]

    return res

# Cell
def images_to_vectors(array: np.ndarray, both: bool = False, name_prefix: Optional[str] = None) -> np.ndarray:

    # 2nd and 3rd dimensions are assumed to have the same size
    assert array.shape[1] == array.shape[2]

    N = array.shape[1]

    x_upper, y_upper = np.triu_indices(N, 1)

    x, y = x_upper, y_upper

    if both:

        x_lower, y_lower = np.tril_indices(N, -1)

        x = np.hstack((x_upper, x_lower))
        y = np.hstack((y_upper, y_lower))

    else:

        x, y = x_upper, y_upper

    res = array[:, x, y, ...]

    if name_prefix:

        names = [f'{name_prefix}{i+1}->{j+1}' for i, j in zip(x, y)]

        return res, names

    else:

        return res

# Cell
def to_df(array: np.ndarray, columns_names: Optional[List[str]] = None) -> pd.DataFrame:

    # this yields [0, 0,...0, 1, 1, ...1, 2, 2, ...]
    i_subject = np.repeat(np.arange(array.shape[0]), array.shape[-1])

    # N is the length of the vectors (along the 1st dimension) that are being stacked
    N, n_freqs = array.shape[1:3]

    if columns_names:

        assert len(columns_names) == N

        if n_freqs > 1:

            columns_names = sum(
                [[f'f{i_freq}_{name}' for name in columns_names] for i_freq in range(n_freqs)], [])

#     df = pd.DataFrame(
#         array.transpose((0, 3, 2, 1)).reshape(-1, N*n_freqs), index=i_subject, columns=columns_names)
#     df.index.name = 'subject'
    df = pd.DataFrame(array.transpose((0, 3, 2, 1)).reshape(-1, N*n_freqs), columns=columns_names)
    df['subject'] = i_subject
#     df.insert(0, 'subject', i_subject)

    return df